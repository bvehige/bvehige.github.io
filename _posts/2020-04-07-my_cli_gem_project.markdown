---
layout: post
title:      "*My CLI Gem Project*  "
date:       2020-04-07 08:27:29 +0000
permalink:  my_cli_gem_project
---

![](https://images.unsplash.com/photo-1549488799-496ecb87b5b3?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1567&q=80)

Over the past few weeks I've been working on my first CLI project from scratch.  It's been a fun challenge to try and pull together a lot of the ideas and concepts I've been learning about and execute them in my own small project.  In addition, it was satisfying to see how a project, even a simple one like this, comes together from start to finish.  I got some satisfaction learning more about the basics of how to set up my gem and environment files.  As simple as the final product is, it was still a challenge to bring it to life since everything is still new.  That said, I learned a lot doing this project and have gained some confidence in my ability to utilize the skills I'm being taught.  I find myself wanting to do more of these types of projects as it's certainly how I learn best.

I named my first project Paws.  I'm a dog lover and so when I read the requirements for the project I thought it would be fun to center it around something I love.  As a result I decided to put together a program that would provide a listing of dogs available for adoption from a local animal shelter.  My program would also allow you to make a selection from that listing to learn more information about any particular dog one may be interested in, along with contact information about the shelter in case someone wanted to inquiry about meeting that dog.

My first challenge and one that took me a few different tries, was to find an appropriate website to scrape data from that I felt would be useful to someone really looking for a new dog.  I ran into a lot of websites that were extremely dynamic and seemed difficult to scrape data from that could be successfully iterated over in a way that would work for my project.  Despite using Pry and REPL to test out my data scrapping on each, I actually started and stopped this project a couple of times with shelter websites that I thought would work, only to realize later the data CSS formatting proved very difficult to successfully iterate over once actually executed in my code.  Finally I settled on a local county animal shelter that had all the data I wanted and was formatted in manner that worked for my project.  Persistence proved key as I tried to get going on this project.  I just kept trying despite a few unsuccessful attempts in the beginning.  The silver lining to that is I feel I became a lot more proficient at scrapping and parsing website data and identifying what kind of websites are best to use such a tool.

My second challenge was learning how to approach starting a project from scratch.  After some futzing around in the beginning I realized it was effective to follow the flow chart I had created at the start of the project.  I used that as a guide and began putting together the process of the program itself in the executable file in the bin folder.  As my processes started to take shape it became clearer the methods I needed to write along the way.  I found myself bouncing from class to class, building methods in each that seemed to follow the appropriate flow, based on my chart.  I tried to get one thing working at a time, using fake data to start, just to make sure the actually methods I was writing worked as expected.   Of course it didn't all work right away, but I kept plugging away at each method until I got them working.  Failure really is helpful for me here, as I found myself learning more and more about what I was writing as things failed allowing me to figure out why.  

I ran into one major roadblock that I haven't yet crossed.  In a perfect situation I would like my program to scrape data from a second level of the website I was scraping.  I was struggling with both the execution of scrapping from a second level of the webpage and with the Object Relationship of how to write that code.  Or more specifically, I was unsure when to call the method that would scrape the second level of data.  I did make a few attempts to make that work but I found myself spinning my wheels for too long on that issue.  My project didn't need to complete this second level of scrapping in order to fulfill the requirements of the project so I decided to try and come back to this project in my spare time and complete the second level of scrapped data.  I look forward to learning how to make that work in the near future.     

I really did learn a lot from this first project.  It was nice to put to work many of the things we have been learning about over the first few months of this curriculum.  The labs are great and helpful but for me, working on a project like this really allows me to feel more solid in my execution.  





